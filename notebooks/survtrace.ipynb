{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import warnings\n",
    "import copy\n",
    "import tqdm\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "from utility.survival import (make_time_bins, preprocess_data, convert_to_structured,\n",
    "                              risk_fn, compute_l1_difference, predict_survival_function,\n",
    "                              make_times_hierarchical)\n",
    "from utility.data import (dotdict, format_data, format_data_as_dict_single)\n",
    "from utility.config import load_config\n",
    "from utility.evaluation import global_C_index, local_C_index\n",
    "from data_loader import SeerDataLoader\n",
    "\n",
    "from survtrace.dataset import load_data\n",
    "from survtrace.evaluate_utils import Evaluator\n",
    "from survtrace.utils import set_random_seed\n",
    "from survtrace.model import SurvTraceMulti\n",
    "from survtrace.train_utils import Trainer\n",
    "from survtrace.config import STConfig\n",
    "from utility.data import calculate_vocab_size\n",
    "\n",
    "from data_loader import SeerDataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The 'nopython' keyword.*\")\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Set precision\n",
    "dtype = torch.float64\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and split data\n",
    "dl = SeerDataLoader().load_data(n_samples=10000, device=device, dtype=dtype)\n",
    "df_train, df_valid, df_test = dl.split_data(train_size=0.7, valid_size=0.1, test_size=0.2,\n",
    "                                            random_state=0)\n",
    "n_events = dl.n_events\n",
    "\n",
    "# Preprocess data\n",
    "cat_features = dl.cat_features\n",
    "num_features = dl.num_features\n",
    "X_train = df_train.drop(['event', 'time'], axis=1)\n",
    "X_valid = df_valid.drop(['event', 'time'], axis=1)\n",
    "X_test = df_test.drop(['event', 'time'], axis=1)\n",
    "X_train, X_valid, X_test= preprocess_data(X_train, X_valid, X_test, cat_features,\n",
    "                                            num_features, as_array=True)\n",
    "train_dict = format_data_as_dict_single(X_train, df_train['event'], df_train['time'], dtype)\n",
    "valid_dict = format_data_as_dict_single(X_valid, df_valid['event'], df_valid['time'], dtype)\n",
    "test_dict = format_data_as_dict_single(X_test, df_test['event'], df_test['time'], dtype)\n",
    "n_samples = train_dict['X'].shape[0]\n",
    "n_features = train_dict['X'].shape[1]\n",
    "\n",
    "# Make time bins\n",
    "time_bins = make_time_bins(train_dict['T'], event=None, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "\n",
    "def format_survtrace_data(train_dict, valid_dict, time_bins, n_events):\n",
    "    class LabTransform(LabTransDiscreteTime):\n",
    "        def transform(self, durations, events):\n",
    "            durations, is_event = super().transform(durations, events > 0)\n",
    "            events[is_event == 0] = 0\n",
    "            return durations, events.astype('int64')\n",
    "    train_dict_dh = dict()\n",
    "    train_dict_dh['X'] = train_dict['X'].numpy()\n",
    "    train_dict_dh['E'] = train_dict['E'].numpy()\n",
    "    train_dict_dh['T'] = train_dict['T'].numpy()\n",
    "    valid_dict_dh = dict()\n",
    "    valid_dict_dh['X'] = valid_dict['X'].numpy()\n",
    "    valid_dict_dh['E'] = valid_dict['E'].numpy()\n",
    "    valid_dict_dh['T'] = valid_dict['T'].numpy()\n",
    "    labtrans = LabTransform(time_bins.numpy())\n",
    "    get_target = lambda data: (data['T'], data['E'])\n",
    "    y_train = labtrans.transform(*get_target(train_dict_dh))\n",
    "    y_valid = labtrans.transform(*get_target(valid_dict_dh))\n",
    "    out_features = int(labtrans.out_features)\n",
    "    duration_index = labtrans.cuts\n",
    "    y_train_df, y_valid_df = pd.DataFrame(), pd.DataFrame()\n",
    "    y_train_df['duration'] = y_train[0]\n",
    "    y_train_df['proportion'] = y_train[1]\n",
    "    y_valid_df['duration'] = y_valid[0]\n",
    "    y_valid_df['proportion'] = y_valid[1]\n",
    "    for i in range(n_events):\n",
    "        event_name = \"event_{}\".format(i)\n",
    "        y_train_df[event_name] = (y_train[1] == i+1)*1.0\n",
    "        y_valid_df[event_name] = (y_valid[1] == i+1)*1.0\n",
    "    return y_train_df, y_valid_df, duration_index, out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVTRACE_PARAMS = {\n",
    "    \"num_hidden_layers\": 1,\n",
    "    \"hidden_size\": 32,\n",
    "    \"intermediate_size\": 32,\n",
    "    \"num_attention_heads\": 2,\n",
    "    \"initializer_range\": .02,\n",
    "    \"batch_size\": 128,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 100,\n",
    "    \"early_stop_patience\": 10,\n",
    "    \"hidden_dropout_prob\": 0.25,\n",
    "    \"seed\": 0,\n",
    "    \"hidden_act\": \"gelu\",\n",
    "    \"attention_probs_dropout_prob\": 0.25,\n",
    "    \"layer_norm_eps\": 1000000000000,\n",
    "    \"checkpoint\": \"./checkpoints/survtrace.pt\",\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"chunk_size_feed_forward\": 0,\n",
    "    \"output_attentions\": False,\n",
    "    \"output_hidden_states\": False,\n",
    "    \"tie_word_embeddings\": True,\n",
    "    \"pruned_heads\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "early stops at epoch 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([55.97630148985181,\n",
       "  6.966451897985583,\n",
       "  1.5373863616232106,\n",
       "  1.5204206347874076,\n",
       "  1.5199523139916784,\n",
       "  1.5161057911014815,\n",
       "  1.5179528190546678,\n",
       "  1.5169070183157325,\n",
       "  1.5181505190388975,\n",
       "  1.514900581382812,\n",
       "  1.5142344073398128,\n",
       "  1.5158583275085333,\n",
       "  1.5134622444611585],\n",
       " [54.10038864391313,\n",
       "  1.5550540929984686,\n",
       "  1.5339866592113212,\n",
       "  1.5353198226450724,\n",
       "  1.5367427431346887,\n",
       "  1.5369599987068332,\n",
       "  1.5415617924826341,\n",
       "  1.5379400739079472,\n",
       "  1.5405216051582071,\n",
       "  1.538932658170876,\n",
       "  1.5394357859127086,\n",
       "  1.5396921084820625,\n",
       "  1.5399577247838976])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train survtrace\n",
    "config = dotdict(SURVTRACE_PARAMS)\n",
    "X_train = pd.DataFrame(train_dict['X'], columns=[f'X{i}' for i in range(n_features)])\n",
    "X_valid = pd.DataFrame(valid_dict['X'], columns=[f'X{i}' for i in range(n_features)])\n",
    "cat_features = []\n",
    "num_features = [f'X{i}' for i in range(n_features)]\n",
    "y_train, y_valid, duration_index, out_features = format_survtrace_data(train_dict, valid_dict,\n",
    "                                                                        time_bins, n_events)\n",
    "config['vocab_size'] = calculate_vocab_size(X_train, cat_features)\n",
    "config['duration_index'] = duration_index\n",
    "config['out_feature'] = out_features\n",
    "config['num_numerical_feature'] = int(len(num_features))\n",
    "config['num_categorical_feature'] = int(len(cat_features))\n",
    "config['num_feature'] = n_features\n",
    "config['num_event'] = n_events\n",
    "config['in_features'] = n_features\n",
    "model = SurvTraceMulti(dotdict(config))\n",
    "trainer = Trainer(model)\n",
    "trainer.fit((X_train, y_train), (X_valid, y_valid),\n",
    "            batch_size=config['batch_size'],\n",
    "            epochs=config['epochs'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay'],\n",
    "            val_batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "preds_e1 = model.predict_surv(test_dict['X'], batch_size=config['batch_size'], event=0)\n",
    "preds_e2 = model.predict_surv(test_dict['X'], batch_size=config['batch_size'], event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028],\n",
       "        [1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028],\n",
       "        [1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028],\n",
       "        ...,\n",
       "        [1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028],\n",
       "        [1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028],\n",
       "        [1.0000, 0.9994, 0.9986,  ..., 0.8225, 0.7343, 0.6028]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_e1\n",
    "\n",
    "#TODO: Predictions are the same for all instances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-mensa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
