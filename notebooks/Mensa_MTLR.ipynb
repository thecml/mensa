{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d80c1ba-e8b2-4e41-a11d-5f4592450cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from math import floor\n",
    "\n",
    "import sys,os\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from torchmtlr import MTLRCR, mtlr_neg_log_likelihood, mtlr_risk, mtlr_survival\n",
    "from torchmtlr.utils import make_time_bins, encode_survival, reset_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa161ee-4127-4f39-877f-30abd7e5e807",
   "metadata": {},
   "source": [
    "# Load/preprocess rotterdam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e25b06-5d6d-4e1e-8773-7c849a924d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_events(row):\n",
    "    '''\n",
    "    Censor = 0\n",
    "    Recurrence = 1\n",
    "    Death = 2\n",
    "    '''\n",
    "    event        = row[\"event\"]\n",
    "    \n",
    "    if event==0:\n",
    "        return 0\n",
    "    elif row['rtime'] < row['dtime']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "import config as cfg\n",
    "df = pd.read_csv(f'{cfg.DATA_DIR}/rotterdam.csv')\n",
    "df['time'] = np.minimum(df['rtime'], df['dtime'])\n",
    "df['event'] = df['recur'] | df['death']\n",
    "\n",
    "\n",
    "size_mapping = {\n",
    "    '<=20': 10,\n",
    "    '20-50': 35,\n",
    "    '>50': 75\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df['size_mapped'] = df['size'].replace(size_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb913ace-21c1-4046-b622-9c2d58bd12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = make_time_bins(df[\"time\"], event=df[\"event\"])\n",
    "multi_events = df.apply(lambda x: multiple_events(x), axis=1)\n",
    "\n",
    "'''\n",
    "Normalize the Data\n",
    "'''\n",
    "\n",
    "temp_X_df = df.drop(['pid', 'size', 'rtime', 'recur', 'dtime', 'death', 'time', 'event'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "temp_X_df = pd.DataFrame(scaler.fit_transform(temp_X_df), columns=temp_X_df.columns)\n",
    "\n",
    "y = encode_survival(df[\"time\"], multi_events, time_bins)\n",
    "X = torch.tensor(temp_X_df.values, dtype=torch.float)\n",
    "\n",
    "full_indices = range(len(df))\n",
    "train_indices, test_indices = train_test_split(full_indices, test_size=0.2) # just train & Test\n",
    "# train_indices, val_indices = train_test_split(train_indices, test_size=0.1)\n",
    "\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "# X_train, X_val, X_test = X[train_indices], X[val_indices], X[test_indices]\n",
    "# y_train, y_val, y_test = y[train_indices], y[val_indices], y[test_indices]\n",
    "\n",
    "df_test = df.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302b47d-6b9e-4517-b0fd-c5f9bc5ae980",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650d8965-2b06-4cdb-873a-18234258c0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_optimizer(opt_cls, model, **kwargs):\n",
    "    \"\"\"Creates a PyTorch optimizer for MTLR training.\"\"\"\n",
    "    params_dict = dict(model.named_parameters())\n",
    "    weights = [v for k, v in params_dict.items() if \"mtlr\" not in k and \"bias\" not in k]\n",
    "    biases = [v for k, v in params_dict.items() if \"bias\" in k]\n",
    "    mtlr_weights = [v for k, v in params_dict.items() if \"mtlr_weight\" in k]\n",
    "    # Don't use weight decay on the biases and MTLR parameters, which have\n",
    "    # their own separate L2 regularization\n",
    "    optimizer = opt_cls([\n",
    "        {\"params\": weights},\n",
    "        {\"params\": biases, \"weight_decay\": 0.},\n",
    "        {\"params\": mtlr_weights, \"weight_decay\": 0.},\n",
    "    ], **kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def train_mtlr(x, y, model, time_bins,\n",
    "               num_epochs=1000, lr=.01, weight_decay=0.,\n",
    "               C1=1., batch_size=None,\n",
    "               verbose=True, device=\"cpu\"):\n",
    "    \"\"\"Trains the MTLR model using minibatch gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        MTLR model to train.\n",
    "    data_train : pd.DataFrame\n",
    "        The training dataset. Must contain a `time` column with the\n",
    "        event time for each sample and an `event` column containing\n",
    "        the event indicator.\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        The learning rate.\n",
    "    weight_decay : float\n",
    "        Weight decay strength for all parameters *except* the MTLR\n",
    "        weights. Only used for Deep MTLR training.\n",
    "    C1 : float\n",
    "        L2 regularization (weight decay) strenght for MTLR parameters.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    verbose : bool\n",
    "        Whether to display training progress.\n",
    "    device : str\n",
    "        Device name or ID to use for training.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "    optimizer = make_optimizer(Adam, model, lr=lr, weight_decay=weight_decay)\n",
    "    reset_parameters(model)\n",
    "    print(x.shape, y.shape)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    train_loader = DataLoader(TensorDataset(x, y), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    pbar =  trange(num_epochs, disable=not verbose)\n",
    "    for i in pbar:\n",
    "        for xi, yi in train_loader:\n",
    "            xi, yi = xi.to(device), yi.to(device)\n",
    "            y_pred = model(xi)\n",
    "            loss = mtlr_neg_log_likelihood(y_pred, yi, model, C1, average=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        pbar.set_description(f\"[epoch {i+1: 4}/{num_epochs}]\")\n",
    "        pbar.set_postfix_str(f\"loss = {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4c6001-079a-4966-8f70-6f729e11d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2385, 10]) torch.Size([2385, 86])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  350/350]: 100%|██████████| 350/350 [00:48<00:00,  7.26it/s, loss = 2.6984]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "num_time_bins = len(time_bins)+1\n",
    "in_features = X_train.shape[1]\n",
    "\n",
    "# fit MTLR model \n",
    "mtlr = MTLRCR(in_features=in_features, num_time_bins=num_time_bins, num_events=2) # here is 2 competing risk event            \n",
    "mtlr = train_mtlr(X_train, y_train, mtlr, time_bins, num_epochs=350, \n",
    "                  lr=1e-3, batch_size=64, verbose=True, device=device, C1=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d5852f-8f90-4837-a1a0-a6326c7f5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob       = mtlr(X_test)\n",
    "survival_recur  = mtlr_survival(pred_prob[:,:num_time_bins]).detach().numpy()\n",
    "survival_death = mtlr_survival(pred_prob[:,num_time_bins:]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be633cbf-5527-440d-90ee-58647c111527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recur C-index: 0.6735140106986389\n",
      "death C-index: 0.5449568857561988\n"
     ]
    }
   ],
   "source": [
    "pred_risk = mtlr_risk(pred_prob, 2).detach().numpy()\n",
    "\n",
    "ci_recur  = concordance_index(df_test[\"time\"], -pred_risk[:, 0], event_observed=df_test[\"recur\"]) # 1 is rec\n",
    "ci_death = concordance_index(df_test[\"time\"], -pred_risk[:, 1], event_observed=df_test[\"death\"]) # 2 is death\n",
    "\n",
    "print ('Recur C-index:', ci_recur)\n",
    "print ('death C-index:', ci_death)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
