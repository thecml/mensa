{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import config as cfg\n",
    "from data_loader import get_data_loader\n",
    "from torchmtlr.utils import make_time_bins\n",
    "from utility.survival import preprocess_data\n",
    "\n",
    "matplotlib_style = 'default'\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "plt.rcParams.update({'axes.labelsize': 'medium',\n",
    "                     'axes.titlesize': 'medium',\n",
    "                     'font.size': 14.0,\n",
    "                     'text.usetex': True,\n",
    "                     'text.latex.preamble': r'\\usepackage{amsfonts} \\usepackage{bm}'})\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Setup precision\n",
    "dtype = torch.float64\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "dl = get_data_loader(\"proact_me\").load_data()\n",
    "train_dict, valid_dict, test_dict = dl.split_data(train_size=0.7, valid_size=0.1,\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "n_events = dl.n_events\n",
    "\n",
    "# Preprocess data\n",
    "cat_features = dl.cat_features\n",
    "num_features = dl.num_features\n",
    "event_cols = [f'e{i+1}' for i in range(n_events)]\n",
    "time_cols = [f't{i+1}' for i in range(n_events)]\n",
    "X_train = pd.DataFrame(train_dict['X'], columns=dl.columns)\n",
    "X_valid = pd.DataFrame(valid_dict['X'], columns=dl.columns)\n",
    "X_test = pd.DataFrame(test_dict['X'], columns=dl.columns)\n",
    "X_train, X_valid, X_test = preprocess_data(X_train, X_valid, X_test, cat_features,\n",
    "                                           num_features, as_array=False)\n",
    "feature_names = X_train.columns\n",
    "n_features = train_dict['X'].shape[1]\n",
    "train_dict['X'] = torch.tensor(X_train.to_numpy(), device=device, dtype=dtype)\n",
    "train_dict['E'] = torch.tensor(train_dict['E'], device=device, dtype=torch.int64)\n",
    "train_dict['T'] = torch.tensor(train_dict['T'], device=device, dtype=torch.int64)\n",
    "valid_dict['X'] = torch.tensor(X_valid.to_numpy(), device=device, dtype=dtype)\n",
    "valid_dict['E'] = torch.tensor(valid_dict['E'], device=device, dtype=torch.int64)\n",
    "valid_dict['T'] = torch.tensor(valid_dict['T'], device=device, dtype=torch.int64)\n",
    "test_dict['X'] = torch.tensor(X_test.to_numpy(), device=device, dtype=dtype)\n",
    "test_dict['E'] = torch.tensor(test_dict['E'], device=device, dtype=torch.int64)\n",
    "test_dict['T'] = torch.tensor(test_dict['T'], device=device, dtype=torch.int64)\n",
    "\n",
    "# Make time bins\n",
    "time_bins = make_time_bins(train_dict['T'].cpu(), event=None, dtype=dtype).to(device)\n",
    "time_bins = torch.cat((torch.tensor([0]).to(device), time_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trajectories'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m layers \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrajectories\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m weight_decay \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train 4 models with n_dists = 1, 3, 5, 10\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'trajectories'"
     ]
    }
   ],
   "source": [
    "from mensa.model import MENSA\n",
    "from utility.config import load_config\n",
    "\n",
    "config = load_config(cfg.MENSA_CONFIGS_DIR, \"proact.yaml\")\n",
    "n_epochs = config['n_epochs']\n",
    "n_dists = config['n_dists']\n",
    "lr = config['lr']\n",
    "batch_size = config['batch_size']\n",
    "layers = config['layers']\n",
    "trajectories = config['trajectories']\n",
    "weight_decay = config['weight_decay']\n",
    "\n",
    "# Train 4 models with n_dists = 1, 3, 5, 10\n",
    "trained_models = []\n",
    "for n_dists in [1]: #, 3, 5, 10\n",
    "    model = MENSA(n_features, layers=layers, n_events=n_events,\n",
    "                  n_dists=n_dists, trajectories=trajectories, device=device)\n",
    "    model.fit(train_dict, valid_dict, learning_rate=lr, n_epochs=n_epochs,\n",
    "              weight_decay=weight_decay, patience=10, batch_size=batch_size,\n",
    "              verbose=False)\n",
    "    trained_models.append(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-mensa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
