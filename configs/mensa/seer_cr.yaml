dropout: 0.25
layers: [128, 128, 128]
lr: 0.005
n_epochs: 3000
batch_size: 4096