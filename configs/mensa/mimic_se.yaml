dropout: 0.5
layers: [128, 128]
lr: 0.01
n_epochs: 2000
batch_size: 4096